{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ee6c0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9862fc4-c161-4a3e-96df-962b91520aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5596d5c8-1bbb-4286-bb81-61f12bb75aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_label_path = 'train/with_label'\n",
    "train_no_label_path = 'train/no_label'\n",
    "test_path = 'test'\n",
    "\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "num_classes = 2  #deux types : Clean and Dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "67900ff6-b148-47e7-a997-7f304c1ecaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "#data labélé\n",
    "train_with_label_gen = train_datagen.flow_from_directory(\n",
    "    train_with_label_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#data non labélé\n",
    "unlabeled_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "unlabeled_gen = unlabeled_datagen.flow_from_directory(\n",
    "    train_no_label_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # No labels\n",
    "    shuffle=False\n",
    ")\n",
    "train_data = train_with_label_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c0330f9-9ef4-4cc5-9274-e5159e11727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 667ms/step - accuracy: 0.5000 - loss: 0.8415\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - accuracy: 0.5833 - loss: 1.3752\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5167 - loss: 0.6982 \n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5104 - loss: 0.7165 \n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494ms/step - accuracy: 0.7000 - loss: 0.6797\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5437 - loss: 0.6853 \n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - accuracy: 0.4667 - loss: 0.6847\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6965 \n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - accuracy: 0.5750 - loss: 0.6767\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6729 - loss: 0.6728 \n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.6625 - loss: 0.6716 \n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - accuracy: 0.7917 - loss: 0.6208\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step - accuracy: 0.6333 - loss: 0.6317\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8042 - loss: 0.6409 \n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6354 - loss: 0.5519 \n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - accuracy: 0.7750 - loss: 0.5785\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - accuracy: 0.7833 - loss: 0.5606\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.6792 - loss: 0.5587\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.8042 - loss: 0.4953\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.7604 - loss: 0.4433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2312548c550>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#création de modéle CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "#compilation de modéle \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train do model \n",
    "model.fit(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b9f0a8e4-b284-4813-b5aa-38ef16e46685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('classification_poubelle.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "04b96bf2-c31f-4867-9897-0bbefaaae143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 1 classes.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step\n",
      "Image: test\\0003717662-666x388.jpg - Predicted class: clean\n",
      "Image: test\\00546_01.jpg - Predicted class: dirty\n",
      "Image: test\\00566_02.jpg - Predicted class: dirty\n",
      "Image: test\\00569_03.jpg - Predicted class: clean\n",
      "Image: test\\00594_00.jpg - Predicted class: dirty\n",
      "Image: test\\00798_02.jpg - Predicted class: clean\n",
      "Image: test\\00829_07.jpg - Predicted class: dirty\n",
      "Image: test\\01300_00.jpg - Predicted class: clean\n",
      "Image: test\\01670_07.jpg - Predicted class: clean\n",
      "Image: test\\01787_01.jpg - Predicted class: dirty\n",
      "Image: test\\01906_01.jpg - Predicted class: clean\n",
      "Image: test\\02136_04.jpg - Predicted class: dirty\n",
      "Image: test\\02248_00.jpg - Predicted class: dirty\n",
      "Image: test\\02587_03.jpg - Predicted class: clean\n",
      "Image: test\\02752_02.jpg - Predicted class: clean\n",
      "Image: test\\02887_03.jpg - Predicted class: dirty\n",
      "Image: test\\03060_07.jpg - Predicted class: clean\n",
      "Image: test\\03213_03.jpg - Predicted class: dirty\n",
      "Image: test\\0dd71fdd2db2d0beb278eddb5692a156fb79a40c.temp.jpeg - Predicted class: dirty\n",
      "Image: test\\1080.full.jpeg - Predicted class: clean\n",
      "Image: test\\1300.full.jpeg - Predicted class: clean\n",
      "Image: test\\1576.full.jpeg - Predicted class: dirty\n",
      "Image: test\\1700.full.jpeg - Predicted class: dirty\n",
      "Image: test\\1794.full.jpeg - Predicted class: clean\n",
      "Image: test\\1992.full.jpeg - Predicted class: dirty\n",
      "Image: test\\20161214fg_0056_1200w.jpg - Predicted class: clean\n",
      "Image: test\\2752.full.jpeg - Predicted class: dirty\n",
      "Image: test\\42c85ef764ff1f8b34baad092bc87341f3b8e82f.temp.jpeg - Predicted class: clean\n",
      "Image: test\\4908.full.jpeg - Predicted class: clean\n",
      "Image: test\\5282.full.jpeg - Predicted class: dirty\n",
      "Image: test\\5440.full.jpeg - Predicted class: dirty\n",
      "Image: test\\5533.full.jpeg - Predicted class: clean\n",
      "Image: test\\850.full.jpeg - Predicted class: dirty\n",
      "Image: test\\908.full.jpeg - Predicted class: clean\n",
      "Image: test\\9d3051c4eee56a8149ed45d695d85093e6eee9a5.temp.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-08 at 2.18.58 PM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-08 at 2.21.54 PM (4).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-09 at 2.08.14 PM (3).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-10 at 3.38.05 PM (11).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-10 at 4.59.16 PM (8).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-10 at 5.07.37 PM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-10 at 5.07.37 PM (5).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-11 at 12.41.25 AM (5).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-12 at 9.01.11 AM (27).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-18 at 11.21.17 AM (6).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-18 at 11.57.03 AM (5).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-24 at 5.18.12 PM (5).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-05-24 at 5.18.12 PM (8).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-05-24 at 5.24.32 PM (6).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-06-29 at 8.55.43 AM (1).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-07-06 at 9.41.53 AM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-07-11 at 5.57.47 PM (6).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-07-11 at 8.43.02 PM (1).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-07-12 at 6.25.07 PM (2).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-08-11 at 9.54.56 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-08-20 at 9.03.05 AM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-08-21 at 9.54.56 AM (4).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-08-25 at 12.56.50 PM (2).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-08-27 at 3.44.11 PM (5).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-09-21 at 8.53.14 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-09-21 at 8.53.15 AM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-09-24 at 8.49.45 AM (3).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-09-27 at 5.34.18 PM (3).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-09-27 at 6.47.12 PM (2).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-09-30 at 4.07.03 PM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-09-30 at 4.07.58 PM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-03 at 1.20.09 PM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-04 at 10.35.23 AM (9).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-04 at 10.35.23 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-10 at 12.11.11 PM (2).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-10 at 2.40.51 PM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-14 at 10.34.29 PM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-15 at 9.23.28 AM (2).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-20 at 7.14.11 PM (10).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-20 at 7.29.51 PM (2).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-26 at 9.19.12 AM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-26 at 9.19.14 AM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-10-26 at 9.25.11 AM (2).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-10-27 at 9.33.26 AM (19).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-11-02 at 7.23.13 PM (5).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-11-16 at 8.37.14 PM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-25 at 1.00.10 PM (3).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.36.51 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.36.52 AM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.36.54 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.38.09 AM (4).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.38.10 AM (2).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.39.52 AM (1).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.39.52 AM (2).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.39.54 AM (5).jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 12.40.49 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2020-12-26 at 4.28.25 PM.jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2020-12-30 at 9.05.14 AM (1).jpeg - Predicted class: clean\n",
      "Image: test\\WhatsApp Image 2021-01-11 at 9.15.38 AM.jpeg - Predicted class: dirty\n",
      "Image: test\\WhatsApp Image 2021-01-29 at 6.23.22 PM.jpeg - Predicted class: dirty\n",
      "Image: test\\b0cf2c54e4558b1171d4cb3b92dd7287fab0d964.temp.jpeg - Predicted class: clean\n",
      "Image: test\\b4582c0689d487a40b80d52f2bfb5abfa9304228.temp.jpeg - Predicted class: dirty\n",
      "Image: test\\basura-702x395.jpg - Predicted class: clean\n",
      "Image: test\\dsc0132_4.jpg.png - Predicted class: dirty\n",
      "Image: test\\fc026b24f61b2165d89b588538270940d3dc700b.temp.jpeg - Predicted class: clean\n"
     ]
    }
   ],
   "source": [
    "#evaluation de modéle avec les imaes test \n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on test data using the test generator\n",
    "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "\n",
    "# Convert predictions to class labels (0 or 1)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Get the filenames of the test images\n",
    "filenames = test_generator.filenames\n",
    "\n",
    "# Print predicted classes for test images with filenames\n",
    "for filename, predicted_class in zip(filenames, predicted_classes.flatten()):\n",
    "    print(f\"Image: {filename} - Predicted class: {'dirty' if predicted_class == 1 else 'clean'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "555e7a5d-2681-40e4-85a1-934a9b61d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmppa_r4oj4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmppa_r4oj4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\USER\\AppData\\Local\\Temp\\tmppa_r4oj4'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='keras_tensor_1455')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2410101393888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410101393712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102101264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102101088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102103200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102102848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102126016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102125840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102127952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2410102127600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "#deploiment de modéle pour l'application mobile\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('classification_poubelle.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607d332-b5fe-41ca-bc91-f5f185dd2d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
